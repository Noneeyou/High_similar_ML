{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb2dd5ab",
   "metadata": {},
   "source": [
    "# tdmsåŸå§‹æ•°æ®è¯»å– \n",
    "## ä¸è¦éšä¾¿è¿è¡Œï¼Œ æ³¨é‡Šæ‰äº†ï¼Œè¦ç”¨å†è§£é™¤æ³¨é‡Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70509c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/charles/HZU/Industrial_Software_Testing/Industrial_Software_Testing/High_similar_ML/data_process\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(\"ğŸ“Œ Project root set to:\", PROJECT_ROOT)\n",
    "\n",
    "\n",
    "from my_lib.KAIST.KAIST_utils import process_kaist_file\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# 1. åŸå§‹ TDMS æ–‡ä»¶åˆ—è¡¨\n",
    "# =========================\n",
    "tdms_files = [\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFI_03.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFI_10.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFI_30.tdms\",\n",
    "\n",
    "    # \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_03.tdms\",\n",
    "    # \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_10.tdms\",\n",
    "    # \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_30.tdms\",\n",
    "\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Misalign_01.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Misalign_03.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Misalign_05.tdms\",\n",
    "\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Normal.tdms\",\n",
    "\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Unbalance_0583mg.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Unbalance_1169mg.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Unbalance_1751mg.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Unbalance_2239mg.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_Unbalance_3318mg.tdms\",\n",
    "]\n",
    "\n",
    "\n",
    "# =========================\n",
    "# 2. ä¿å­˜ç›®å½•ï¼ˆLinux ä¾§ï¼‰\n",
    "# =========================\n",
    "save_dir = Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 3. æ‰¹é‡å¤„ç†\n",
    "# =========================\n",
    "saved_csv_files = []\n",
    "\n",
    "for tdms_path in tdms_files:\n",
    "    print(f\"ğŸš€ Processing: {tdms_path}\")\n",
    "    out_csv = process_kaist_file(\n",
    "        file_path=tdms_path,\n",
    "        save_dir=str(save_dir),\n",
    "        data_type=\"temperature_current\"\n",
    "    )\n",
    "    saved_csv_files.append(out_csv)\n",
    "    print(f\"âœ… Saved to: {out_csv}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ Done! Total files processed: {len(saved_csv_files)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f0a0f",
   "metadata": {},
   "source": [
    "### é’ˆå¯¹BPFOæ•°æ®è¿›è¡Œå•ç‹¬å¤„ç†ï¼Œè¿™äº›æ•°æ®åº”è¯¥æ˜¯æ‰€æœ‰æ—¶é—´ç‚¹éƒ½æœ‰ç¼ºå¤±ï¼Œæ‰€ä»¥ç”¨ä¸Šé¢çš„é€»è¾‘æå–å‡ºæ¥æ˜¯ç©ºæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd043e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸš€ Processing /home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_03.tdms\n",
      "âœ… cDAQ9185-1F486B5Mod1_ai0: 1536492 samples\n",
      "âœ… cDAQ9185-1F486B5Mod1_ai1: 1536492 samples\n",
      "âœ… cDAQ9185-1F486B5Mod2_ai0: 1536492 samples\n",
      "âš ï¸ cDAQ9185-1F486B5Mod2_ai2: empty\n",
      "âš ï¸ cDAQ9185-1F486B5Mod2_ai3: empty\n",
      "ğŸ’¾ Saved: /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_03.csv | shape=(1536492, 6)\n",
      "============================================================\n",
      "ğŸš€ Processing /home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_10.tdms\n",
      "âœ… cDAQ9185-1F486B5Mod1_ai0: 1536492 samples\n",
      "âœ… cDAQ9185-1F486B5Mod1_ai1: 1536492 samples\n",
      "âœ… cDAQ9185-1F486B5Mod2_ai0: 1536492 samples\n",
      "âš ï¸ cDAQ9185-1F486B5Mod2_ai2: empty\n",
      "âš ï¸ cDAQ9185-1F486B5Mod2_ai3: empty\n",
      "ğŸ’¾ Saved: /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_10.csv | shape=(1536492, 6)\n",
      "============================================================\n",
      "ğŸš€ Processing /home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_30.tdms\n",
      "âœ… cDAQ9185-1F486B5Mod1_ai0: 1536492 samples\n",
      "âœ… cDAQ9185-1F486B5Mod1_ai1: 1536492 samples\n",
      "âœ… cDAQ9185-1F486B5Mod2_ai0: 1536492 samples\n",
      "âš ï¸ cDAQ9185-1F486B5Mod2_ai2: empty\n",
      "âš ï¸ cDAQ9185-1F486B5Mod2_ai3: empty\n",
      "ğŸ’¾ Saved: /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_30.csv | shape=(1536492, 6)\n",
      "\n",
      "ğŸ‰ All done!\n",
      " - /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_03.csv\n",
      " - /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_10.csv\n",
      " - /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_30.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# â­ å• Cellï¼šKAIST TDMS â†’ CSVï¼ˆcurrent & tempï¼‰\n",
    "#    - è‡ªåŠ¨è¯†åˆ« Log ç»„\n",
    "#    - ç¬¬ä¸€åˆ—ç»Ÿä¸€ä¸º timestamp\n",
    "#    - æ‰€æœ‰é€šé“å¯¹é½é•¿åº¦\n",
    "#    - ç©ºå€¼å¡« null\n",
    "#    - ä¸åŒ…å« label\n",
    "# ============================================================\n",
    "\n",
    "from nptdms import TdmsFile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# =========================\n",
    "# 1ï¸âƒ£ TDMS æ–‡ä»¶åˆ—è¡¨\n",
    "# =========================\n",
    "tdms_files = [\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_03.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_10.tdms\",\n",
    "    \"/home/charles/HZU/Data_raw/KAIST/Vibration, Acoustic, Temperature, and Motor Current Dataset of Rotating Machine Under Varying Load Conditions for Fault Diagnosis/current,temp/0Nm_BPFO_30.tdms\",\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 2ï¸âƒ£ è¾“å‡ºç›®å½•\n",
    "# =========================\n",
    "save_dir = Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw\")\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 3ï¸âƒ£ è½¬æ¢å‡½æ•°\n",
    "# =========================\n",
    "def tdms_to_csv(tdms_path, save_dir, fs=None):\n",
    "    \"\"\"\n",
    "    fs:\n",
    "      - None  -> ä½¿ç”¨ sample index ä½œä¸º timestamp\n",
    "      - æ•°å€¼  -> timestamp = index / fs\n",
    "    \"\"\"\n",
    "    tdms = TdmsFile.read(tdms_path)\n",
    "    log_group = tdms[\"Log\"]\n",
    "\n",
    "    channel_data = {}\n",
    "    max_len = 0\n",
    "\n",
    "    # è¯»å–æ‰€æœ‰ channel\n",
    "    for ch in log_group.channels():\n",
    "        data = ch[:]\n",
    "        name = ch.name.replace(\"/\", \"_\")  # åˆ—åå®‰å…¨åŒ–\n",
    "\n",
    "        if len(data) > 0:\n",
    "            channel_data[name] = data\n",
    "            max_len = max(max_len, len(data))\n",
    "            print(f\"âœ… {name}: {len(data)} samples\")\n",
    "        else:\n",
    "            channel_data[name] = []\n",
    "            print(f\"âš ï¸ {name}: empty\")\n",
    "\n",
    "    # =========================\n",
    "    # ç”Ÿæˆ timestampï¼ˆç¬¬ä¸€åˆ—ï¼‰\n",
    "    # =========================\n",
    "    if fs is None:\n",
    "        # ç”¨ sample indexï¼ˆæœ€ç¨³ï¼Œä¸å¼•å…¥å‡ç‰©ç†æ„ä¹‰ï¼‰\n",
    "        timestamp = np.arange(max_len)\n",
    "    else:\n",
    "        # ç”¨çœŸå®é‡‡æ ·ç‡\n",
    "        timestamp = np.arange(max_len) / fs\n",
    "\n",
    "    aligned_data = {\"timestamp\": timestamp}\n",
    "\n",
    "    # =========================\n",
    "    # å¯¹é½é€šé“é•¿åº¦\n",
    "    # =========================\n",
    "    for name, data in channel_data.items():\n",
    "        if len(data) == 0:\n",
    "            aligned_data[name] = [np.nan] * max_len\n",
    "        elif len(data) < max_len:\n",
    "            aligned_data[name] = np.pad(\n",
    "                data,\n",
    "                (0, max_len - len(data)),\n",
    "                constant_values=np.nan\n",
    "            )\n",
    "        else:\n",
    "            aligned_data[name] = data\n",
    "\n",
    "    df = pd.DataFrame(aligned_data)\n",
    "\n",
    "    out_csv = save_dir / f\"{Path(tdms_path).stem}.csv\"\n",
    "    df.to_csv(out_csv, index=False, na_rep=\"null\")\n",
    "\n",
    "    print(f\"ğŸ’¾ Saved: {out_csv} | shape={df.shape}\")\n",
    "    return out_csv\n",
    "\n",
    "# =========================\n",
    "# 4ï¸âƒ£ æ‰¹é‡æ‰§è¡Œ\n",
    "# =========================\n",
    "saved_files = []\n",
    "\n",
    "for tdms_path in tdms_files:\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸš€ Processing {tdms_path}\")\n",
    "    out = tdms_to_csv(tdms_path, save_dir, fs=None)  # fs=None â†’ timestamp ä¸ºç´¢å¼•\n",
    "    saved_files.append(out)\n",
    "\n",
    "print(\"\\nğŸ‰ All done!\")\n",
    "for f in saved_files:\n",
    "    print(\" -\", f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec1cad",
   "metadata": {},
   "source": [
    "## é‡å†™åˆ—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 1. è¾“å…¥ / è¾“å‡ºç›®å½•\n",
    "# =========================\n",
    "src_dir = Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw\")\n",
    "dst_dir = Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_withlabel\")\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 2. åŸå§‹ â†’ æ ‡å‡†åˆ—åæ˜ å°„\n",
    "# =========================\n",
    "column_rename_map = {\n",
    "    \"timestamp\": \"timestamp\",\n",
    "\n",
    "    \"cDAQ9185-1F486B5Mod1/ai0\": \"Temp_A(Â°C)\",\n",
    "    \"cDAQ9185-1F486B5Mod1/ai1\": \"Temp_B(Â°C)\",\n",
    "\n",
    "    \"cDAQ9185-1F486B5Mod2/ai0\": \"I_U(A)\",\n",
    "    \"cDAQ9185-1F486B5Mod2/ai2\": \"I_V(A)\",\n",
    "    \"cDAQ9185-1F486B5Mod2/ai3\": \"I_W(A)\",\n",
    "}\n",
    "\n",
    "raw_cols = set(column_rename_map.keys())\n",
    "std_cols = set(column_rename_map.values())\n",
    "\n",
    "# =========================\n",
    "# 3. æ‰¹é‡å¤„ç†\n",
    "# =========================\n",
    "csv_files = sorted(src_dir.glob(\"*.csv\"))\n",
    "print(f\"ğŸ“‚ Found {len(csv_files)} CSV files\")\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    print(f\"\\nğŸ”„ Processing: {csv_path.name}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    cols = set(df.columns)\n",
    "\n",
    "    # =========================\n",
    "    # â‘  å¦‚æœå·²ç»æ˜¯æ ‡å‡†åˆ—å â†’ è·³è¿‡\n",
    "    # =========================\n",
    "    if std_cols.issubset(cols):\n",
    "        print(\"â­ï¸ å·²æ˜¯æ ‡å‡†åˆ—åï¼Œè·³è¿‡å¤„ç†\")\n",
    "        out_path = dst_dir / csv_path.name\n",
    "        df.to_csv(out_path, index=False)\n",
    "        continue\n",
    "\n",
    "    # =========================\n",
    "    # â‘¡ å¦åˆ™ï¼Œæ£€æŸ¥æ˜¯å¦å…·å¤‡åŸå§‹åˆ—\n",
    "    # =========================\n",
    "    missing_raw = raw_cols - cols\n",
    "    if missing_raw:\n",
    "        raise ValueError(\n",
    "            f\"{csv_path.name} ç¼ºå°‘åŸå§‹åˆ—ï¼Œä¸”ä¸æ˜¯æ ‡å‡†æ ¼å¼: {missing_raw}\"\n",
    "        )\n",
    "\n",
    "    # =========================\n",
    "    # â‘¢ æ‰§è¡Œé‡å‘½å\n",
    "    # =========================\n",
    "    df = df.rename(columns=column_rename_map)\n",
    "\n",
    "    # å†æ¬¡æ ¡éªŒ\n",
    "    missing_after = std_cols - set(df.columns)\n",
    "    if missing_after:\n",
    "        raise ValueError(\n",
    "            f\"{csv_path.name} é‡å‘½ååç¼ºå°‘æ ‡å‡†åˆ—: {missing_after}\"\n",
    "        )\n",
    "\n",
    "    # =========================\n",
    "    # â‘£ ä¿å­˜\n",
    "    # =========================\n",
    "    out_path = dst_dir / csv_path.name\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"âœ… åˆ—åå·²ç»Ÿä¸€ï¼Œä¿å­˜åˆ°: {out_path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb310e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4536e1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_03.csv\n",
      "âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_withlabel/0Nm_BPFO_03.csv\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_10.csv\n",
      "âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_withlabel/0Nm_BPFO_10.csv\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_30.csv\n",
      "âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_withlabel/0Nm_BPFO_30.csv\n",
      "\n",
      "ğŸ‰ è¿™ä¸‰ä¸ªæ–‡ä»¶å·²å•ç‹¬å¤„ç†å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 1ï¸âƒ£ æŒ‡å®šè¿™ä¸‰ä¸ªæ–‡ä»¶\n",
    "# =========================\n",
    "csv_files = [\n",
    "    Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_03.csv\"),\n",
    "    Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_10.csv\"),\n",
    "    Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw/0Nm_BPFO_30.csv\"),\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# 2ï¸âƒ£ è¾“å‡ºç›®å½•\n",
    "# =========================\n",
    "dst_dir = Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_withlabel\")\n",
    "dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# =========================\n",
    "# 3ï¸âƒ£ åˆ—åæ˜ å°„è§„åˆ™\n",
    "# =========================\n",
    "column_rename_map = {\n",
    "    \"timestamp\": \"timestamp\",\n",
    "\n",
    "    \"cDAQ9185-1F486B5Mod1_ai0\": \"Temp_A(Â°C)\",\n",
    "    \"cDAQ9185-1F486B5Mod1_ai1\": \"Temp_B(Â°C)\",\n",
    "\n",
    "    \"cDAQ9185-1F486B5Mod2_ai0\": \"I_U(A)\",\n",
    "    \"cDAQ9185-1F486B5Mod2_ai2\": \"I_V(A)\",\n",
    "    \"cDAQ9185-1F486B5Mod2_ai3\": \"I_W(A)\",\n",
    "}\n",
    "\n",
    "raw_cols = set(column_rename_map.keys())\n",
    "std_cols = set(column_rename_map.values())\n",
    "\n",
    "# =========================\n",
    "# 4ï¸âƒ£ å•ç‹¬å¤„ç†\n",
    "# =========================\n",
    "for csv_path in csv_files:\n",
    "    print(f\"\\nğŸ”„ Processing: {csv_path.name}\")\n",
    "\n",
    "    if not csv_path.exists():\n",
    "        print(\"âŒ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "    cols = set(df.columns)\n",
    "\n",
    "    # å·²ç»æ˜¯æ ‡å‡†åˆ—å â†’ ç›´æ¥æ‹·è´\n",
    "    if std_cols.issubset(cols):\n",
    "        print(\"â­ï¸ å·²æ˜¯æ ‡å‡†åˆ—åï¼Œç›´æ¥ä¿å­˜\")\n",
    "        out_path = dst_dir / csv_path.name\n",
    "        df.to_csv(out_path, index=False)\n",
    "        continue\n",
    "\n",
    "    # æ£€æŸ¥åŸå§‹åˆ—æ˜¯å¦é½å…¨\n",
    "    missing_raw = raw_cols - cols\n",
    "    if missing_raw:\n",
    "        raise ValueError(\n",
    "            f\"{csv_path.name} ç¼ºå°‘åŸå§‹åˆ—ï¼Œä¸”ä¸æ˜¯æ ‡å‡†æ ¼å¼: {missing_raw}\"\n",
    "        )\n",
    "\n",
    "    # é‡å‘½å\n",
    "    df = df.rename(columns=column_rename_map)\n",
    "\n",
    "    # å†æ ¡éªŒ\n",
    "    missing_after = std_cols - set(df.columns)\n",
    "    if missing_after:\n",
    "        raise ValueError(\n",
    "            f\"{csv_path.name} é‡å‘½ååç¼ºå°‘æ ‡å‡†åˆ—: {missing_after}\"\n",
    "        )\n",
    "\n",
    "    out_path = dst_dir / csv_path.name\n",
    "    df.to_csv(out_path, index=False)\n",
    "\n",
    "    print(f\"âœ… å¤„ç†å®Œæˆï¼Œä¿å­˜åˆ°: {out_path}\")\n",
    "\n",
    "print(\"\\nğŸ‰ è¿™ä¸‰ä¸ªæ–‡ä»¶å·²å•ç‹¬å¤„ç†å®Œæˆã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b137693d",
   "metadata": {},
   "source": [
    "## åŠ å…¥æ ‡ç­¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8828d961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Found 15 CSV files\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFI_03.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFI_10.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFI_30.csv\n",
      "âœ… Added label=4 to 0Nm_BPFI_30.csv\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_03.csv\n",
      "âœ… Added label=5 to 0Nm_BPFO_03.csv\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_10.csv\n",
      "âœ… Added label=6 to 0Nm_BPFO_10.csv\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_30.csv\n",
      "âœ… Added label=7 to 0Nm_BPFO_30.csv\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Misalign_01.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Misalign_03.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Misalign_05.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Normal.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_0583mg.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_1169mg.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_1751mg.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_2239mg.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_3318mg.csv\n",
      "â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\n",
      "\n",
      "ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆã€‚\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# =========================\n",
    "# 1. æ•°æ®ç›®å½•\n",
    "# =========================\n",
    "data_dir = Path(\"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_withlabel\")\n",
    "\n",
    "# =========================\n",
    "# 2. æ–‡ä»¶å â†’ æ ‡ç­¾ æ˜ å°„è¡¨\n",
    "# =========================\n",
    "label_map = {\n",
    "    \"0Nm_Normal\": 1,\n",
    "\n",
    "    \"0Nm_BPFI_03\": 2,\n",
    "    \"0Nm_BPFI_10\": 3,\n",
    "    \"0Nm_BPFI_30\": 4,\n",
    "\n",
    "    \"0Nm_BPFO_03\": 5,\n",
    "    \"0Nm_BPFO_10\": 6,\n",
    "    \"0Nm_BPFO_30\": 7,\n",
    "\n",
    "    \"0Nm_Misalign_01\": 8,\n",
    "    \"0Nm_Misalign_03\": 9,\n",
    "    \"0Nm_Misalign_05\": 10,\n",
    "\n",
    "    \"0Nm_Unbalance_0583mg\": 11,\n",
    "    \"0Nm_Unbalance_1169mg\": 12,\n",
    "    \"0Nm_Unbalance_1751mg\": 13,\n",
    "    \"0Nm_Unbalance_2239mg\": 14,\n",
    "    \"0Nm_Unbalance_3318mg\": 15,\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# 3. æ‰¹é‡å¤„ç†\n",
    "# =========================\n",
    "csv_files = sorted(data_dir.glob(\"*.csv\"))\n",
    "print(f\"ğŸ“‚ Found {len(csv_files)} CSV files\")\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    stem = csv_path.stem\n",
    "    print(f\"\\nğŸ”„ Processing: {csv_path.name}\")\n",
    "\n",
    "    # ---------- â‘  å·²æœ‰ label åˆ— â†’ è·³è¿‡ ----------\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if \"label\" in df.columns:\n",
    "        print(\"â­ï¸ å·²å­˜åœ¨ label åˆ—ï¼Œè·³è¿‡\")\n",
    "        continue\n",
    "\n",
    "    # ---------- â‘¡ æ–‡ä»¶åæ ¡éªŒ ----------\n",
    "    if stem not in label_map:\n",
    "        raise ValueError(f\"âŒ æ–‡ä»¶åæœªåœ¨æ˜ å°„è¡¨ä¸­: {csv_path.name}\")\n",
    "\n",
    "    label = label_map[stem]\n",
    "\n",
    "    # ---------- â‘¢ æ·»åŠ  label ----------\n",
    "    df[\"label\"] = label\n",
    "\n",
    "    # ---------- â‘£ è¦†ç›–ä¿å­˜ ----------\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"âœ… Added label={label} to {csv_path.name}\")\n",
    "\n",
    "print(\"\\nğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆã€‚\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3504c",
   "metadata": {},
   "source": [
    "## æå–æ¯ä¸ªæ ·æœ¬5000ä¸ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad8ede4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” å…±å‘ç° 15 ä¸ªç±»åˆ«æ–‡ä»¶\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFI_03\n",
      "âœ… 0Nm_BPFI_03: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFI_10\n",
      "âœ… 0Nm_BPFI_10: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFI_30\n",
      "âœ… 0Nm_BPFI_30: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_03\n",
      "âœ… 0Nm_BPFO_03: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_10\n",
      "âœ… 0Nm_BPFO_10: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_BPFO_30\n",
      "âœ… 0Nm_BPFO_30: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Misalign_01\n",
      "âœ… 0Nm_Misalign_01: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Misalign_03\n",
      "âœ… 0Nm_Misalign_03: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Misalign_05\n",
      "âœ… 0Nm_Misalign_05: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Normal\n",
      "âœ… 0Nm_Normal: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_0583mg\n",
      "âœ… 0Nm_Unbalance_0583mg: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_1169mg\n",
      "âœ… 0Nm_Unbalance_1169mg: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_1751mg\n",
      "âœ… 0Nm_Unbalance_1751mg: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_2239mg\n",
      "âœ… 0Nm_Unbalance_2239mg: 5000 samples\n",
      "\n",
      "ğŸ”„ Processing: 0Nm_Unbalance_3318mg\n",
      "âœ… 0Nm_Unbalance_3318mg: 5000 samples\n",
      "============================================================\n",
      "ğŸ‰ åˆå¹¶å®Œæˆ\n",
      "ğŸ“ è¾“å‡ºè·¯å¾„: /home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_wl_5000/0Nm_all_classes_merged_5000.csv\n",
      "ğŸ“Š æ€»æ ·æœ¬æ•°: 75000\n",
      "ğŸ“ˆ å„ç±»åˆ«æ ·æœ¬ç»Ÿè®¡ï¼š\n",
      "label\n",
      "2     5000\n",
      "3     5000\n",
      "4     5000\n",
      "5     5000\n",
      "6     5000\n",
      "7     5000\n",
      "8     5000\n",
      "9     5000\n",
      "10    5000\n",
      "1     5000\n",
      "11    5000\n",
      "12    5000\n",
      "13    5000\n",
      "14    5000\n",
      "15    5000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================\n",
    "# 1ï¸âƒ£ è¾“å…¥ / è¾“å‡ºç›®å½•\n",
    "# ==========================\n",
    "src_dir = \"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_withlabel\"\n",
    "dst_dir = \"/home/charles/HZU/Data_processed/HSML/KAIST/current&temp_raw_wl_5000\"\n",
    "os.makedirs(dst_dir, exist_ok=True)\n",
    "\n",
    "output_csv = os.path.join(dst_dir, \"0Nm_all_classes_merged_5000.csv\")\n",
    "\n",
    "samples_per_class = 5000\n",
    "shuffle_each_class = True\n",
    "random_state = 42\n",
    "\n",
    "# ==========================\n",
    "# 2ï¸âƒ£ è¯»å– & æŠ½æ ·\n",
    "# ==========================\n",
    "all_dfs = []\n",
    "\n",
    "csv_files = sorted(\n",
    "    f for f in glob.glob(os.path.join(src_dir, \"*.csv\"))\n",
    "    if not f.endswith(\"_merged.csv\")\n",
    ")\n",
    "\n",
    "assert len(csv_files) > 0, \"âŒ è¾“å…¥ç›®å½•ä¸‹æ²¡æœ‰å¯ç”¨ CSV æ–‡ä»¶\"\n",
    "\n",
    "print(f\"ğŸ” å…±å‘ç° {len(csv_files)} ä¸ªç±»åˆ«æ–‡ä»¶\")\n",
    "\n",
    "for csv_path in csv_files:\n",
    "    class_name = os.path.basename(csv_path).replace(\".csv\", \"\")\n",
    "    print(f\"\\nğŸ”„ Processing: {class_name}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # --------------------------\n",
    "    # label å¿…é¡»å­˜åœ¨ï¼ˆä½ å‰ä¸€æ­¥å·²ç»ç»Ÿä¸€è¿‡ï¼‰\n",
    "    # --------------------------\n",
    "    if \"label\" not in df.columns:\n",
    "        raise ValueError(f\"{class_name} ç¼ºå°‘ label åˆ—ï¼Œè¯·å…ˆæ£€æŸ¥ä¸Šæ¸¸æ­¥éª¤\")\n",
    "\n",
    "    # --------------------------\n",
    "    # æŠ½æ ·\n",
    "    # --------------------------\n",
    "    if len(df) >= samples_per_class:\n",
    "        df_sampled = df.sample(\n",
    "            n=samples_per_class,\n",
    "            replace=False,\n",
    "            random_state=random_state if shuffle_each_class else None\n",
    "        )\n",
    "    else:\n",
    "        print(f\"âš ï¸ {class_name} æ ·æœ¬ä¸è¶³ {samples_per_class}ï¼Œä»…æœ‰ {len(df)}ï¼Œå·²å…¨éƒ¨ä½¿ç”¨\")\n",
    "        df_sampled = df\n",
    "\n",
    "    df_sampled[\"source_file\"] = class_name\n",
    "    all_dfs.append(df_sampled)\n",
    "\n",
    "    print(f\"âœ… {class_name}: {len(df_sampled)} samples\")\n",
    "\n",
    "# ==========================\n",
    "# 3ï¸âƒ£ åˆå¹¶ & ä¿å­˜\n",
    "# ==========================\n",
    "merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "merged_df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ‰ åˆå¹¶å®Œæˆ\")\n",
    "print(f\"ğŸ“ è¾“å‡ºè·¯å¾„: {output_csv}\")\n",
    "print(f\"ğŸ“Š æ€»æ ·æœ¬æ•°: {len(merged_df)}\")\n",
    "print(\"ğŸ“ˆ å„ç±»åˆ«æ ·æœ¬ç»Ÿè®¡ï¼š\")\n",
    "print(merged_df[\"label\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
